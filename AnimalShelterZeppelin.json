{"paragraphs":[{"text":"%md\nI'll work on the following Kaggle problem: https://www.kaggle.com/c/shelter-animal-outcomes\n\nFirst, I did an [exploratory data analysis](https://public.tableau.com/views/AnimalShelterOutcomes/OutcomebyTop10Colors?:embed=y&:display_count=yes).\n\nFrom the analysis, it seems age is highly predictive, as is sex. The animal type (cat or dog) also matters a good deal. The breed and color are less predictive.","dateUpdated":"2016-09-19T09:53:33-0400","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474233943673_-1034364421","id":"20160918-172543_916453733","result":{"code":"SUCCESS","type":"HTML","msg":"<p>I'll work on the following Kaggle problem: https://www.kaggle.com/c/shelter-animal-outcomes</p>\n<p>First, I did an <a href=\"https://public.tableau.com/views/AnimalShelterOutcomes/OutcomebyTop10Colors?:embed=y&amp;:display_count=yes\">exploratory data analysis</a>.</p>\n<p>From the analysis, it seems age is highly predictive, as is sex. The animal type (cat or dog) also matters a good deal. The breed and color are less predictive.</p>\n"},"dateCreated":"2016-09-18T05:25:43-0400","dateStarted":"2016-09-19T09:53:33-0400","dateFinished":"2016-09-19T09:53:34-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:181"},{"text":"import org.apache.spark.sql.functions.udf\n\n// From Kaggle Competition: https://www.kaggle.com/c/shelter-animal-outcomes/\nval PATH_TO_INPUT_DATA = \"/Users/harihar/Downloads/train.csv\"\n\n// We'll read the AgeUponOutcome and convert that to the number of years.\nval parseAge = udf((ageStr: String) => {\n    if (ageStr == \"Unknown\") {\n        0\n    } else {\n        val split = ageStr.split(\" \")\n        val age = split(0).toInt\n        val numPerYear = split(1) match {\n            case \"days\" | \"day\" => 365\n            case \"month\" | \"months\" => 12\n            case \"week\" | \"weeks\" => 52\n            case \"years\" | \"year\" => 1\n            case _ => 1\n        }\n        age / 1.0 / numPerYear\n    }\n})\n\n// Instead of using all the breeds, we'll use the give most common breeds.\nval groupBreed = udf((breedStr: String) => \n    if (Set(\"Domestic Shorthair Mix\", \n            \"Pit Bull Mix\", \n            \"Chihuahua Shorthair Mix\", \n            \"Labrador Retriever Mix\",\n            \"Domestic Medium Hair Mix\").contains(breedStr))\n        breedStr\n    else\n        \"other\"\n)\n\n// Instead of using all the colors, we'll use the ten most common colors.\nval groupColor = udf((colorStr: String) =>\n    if (Set(\"Black/White\",\n            \"Black\",\n            \"Brown Tabby\",\n            \"Brown Tabby/White\",\n            \"White\",\n            \"Brown/White\",\n            \"Orange Tabby\",\n            \"Tan/White\",\n            \"Tricolor\",\n            \"Blue/White\").contains(colorStr))\n        colorStr\n    else\n        \"other\"\n)\n\n// Read the data into a DataFrame.\nval df = spark\n    .read\n    .option(\"header\", true)\n    .option(\"inferSchema\", true)\n    .option(\"ignoreLeadingWhiteSpace\", true)\n    .option(\"ignoreTrailingWhiteSpace\", true)\n    .option(\"nullValue\", \"Unknown\")\n    .option(\"dateFormat\", \"yyyy-MM-dd\")\n    .csv(PATH_TO_INPUT_DATA)\n    .withColumn(\"AgeInYears\", parseAge($\"AgeuponOutcome\"))\n    .withColumn(\"SimpleBreed\", groupBreed($\"Breed\"))\n    .withColumn(\"SimpleColor\", groupColor($\"Color\"))\n\ndf.createOrReplaceTempView(\"df\")","dateUpdated":"2016-09-19T09:53:33-0400","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474232787104_-1670560669","id":"20160918-170627_745740264","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.sql.functions.udf\n\nPATH_TO_INPUT_DATA: String = /Users/harihar/Downloads/train.csv\n\nparseAge: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))\n\ngroupBreed: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n\ngroupColor: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n\ndf: org.apache.spark.sql.DataFrame = [AnimalID: string, Name: string ... 11 more fields]\n"},"dateCreated":"2016-09-18T05:06:27-0400","dateStarted":"2016-09-19T09:53:33-0400","dateFinished":"2016-09-19T09:54:01-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:182"},{"text":"// Preprocess the data and create a feature vector.\n\nimport subramanyam.harihar.sparkmlutils._\n\nval categoricalCols = Array[String](\"AnimalType\", \"SexuponOutcome\", \"SimpleBreed\", \"SimpleColor\")\nval numericalCol = \"AgeInYears\"\nval labelCol = \"OutcomeType\"\nval featuresCol = \"features\"\nval predictionCol = \"prediction\"\n\nval (preprocessedData, featureVectorNames, labelConverterOpt) = FeatureVectorizer(\n    df.toDF(), \n    categoricalCols, \n    Array[String](), \n    labelCol, \n    predictionCol,\n    featuresCol,\n    Array(numericalCol),\n    Some((true, true))\n)(sqlContext)\nval labelConverter = labelConverterOpt.get","dateUpdated":"2016-09-19T09:53:33-0400","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474232763704_-36763597","id":"20160906-144422_1760292807","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport subramanyam.harihar.sparkmlutils._\n\ncategoricalCols: Array[String] = Array(AnimalType, SexuponOutcome, SimpleBreed, SimpleColor)\n\nnumericalCol: String = AgeInYears\n\nlabelCol: String = OutcomeType\n\nfeaturesCol: String = features\n\npredictionCol: String = prediction\n\n\n\npreprocessedData: org.apache.spark.sql.DataFrame = [AnimalID: string, Name: string ... 23 more fields]\nfeatureVectorNames: Array[String] = Array(isDog, isCat, isNeutered Male, isSpayed Female, isIntact Male, isIntact Female, isUnknown, isother, isDomestic Shorthair Mix, isPit Bull Mix, isChihuahua Shorthair Mix, isLabrador Retriever Mix, isDomestic Medium Hair Mix, isother, isBlack/White, isBlack, isBrown Tabby, isBrown Tabby/White, isWhite, isBrown/White, isOrange Tabby, isTan/White, isTricolor, isBlue/White, AgeInYears)\nlabelConverterOpt: Option[org.apache.spark.ml.feature.IndexToString] = Some(idxToStr_416aff6da241)\n\nlabelConverter: org.apache.spark.ml.feature.IndexToString = idxToStr_416aff6da241\n"},"dateCreated":"2016-09-18T05:06:03-0400","dateStarted":"2016-09-19T09:53:35-0400","dateFinished":"2016-09-19T09:54:13-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:183"},{"text":"// Create a cross validated random forest.\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.Pipeline\n\nval Array(rfTrain, rfTest) = preprocessedData.randomSplit(Array(0.7, 0.3))\n\nval rf = new RandomForestClassifier()\n    .setLabelCol(FeatureVectorizer.indexed(labelCol))\n    .setPredictionCol(predictionCol)\n    .setFeaturesCol(featuresCol)\n    .setNumTrees(200)\n    \nval rfPipeline = new Pipeline()\n    .setStages(Array(rf, labelConverter))\n\nval eval = new MulticlassClassificationEvaluator()\n    .setLabelCol(FeatureVectorizer.indexed(labelCol))\n    .setPredictionCol(predictionCol)\n    .setMetricName(\"f1\")\n\nval rfParamGrid = new ParamGridBuilder()\n    .addGrid(rf.featureSubsetStrategy, Array(\"onethird\", \"sqrt\", \"log2\"))\n    .addGrid(rf.impurity, Array(\"gini\", \"entropy\"))\n    .addGrid(rf.maxDepth, Array(5, 7))\n    .build()\n\nval rfCv = new CrossValidator()\n    .setEstimator(rfPipeline)\n    .setEstimatorParamMaps(rfParamGrid)\n    .setEvaluator(eval)\n    .setNumFolds(3)\n\nval rfCvModel = rfCv.fit(rfTrain)\nval rfPredictions = rfCvModel.transform(rfTest)\n\neval.evaluate(rfPredictions)","dateUpdated":"2016-09-19T09:53:33-0400","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474232763705_-37148346","id":"20160909-121704_954791604","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n\nimport org.apache.spark.ml.Pipeline\n\n\nrfTrain: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [AnimalID: string, Name: string ... 23 more fields]\nrfTest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [AnimalID: string, Name: string ... 23 more fields]\n\nrf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_7cc4dc14d713\n\nrfPipeline: org.apache.spark.ml.Pipeline = pipeline_d2838bf3433b\n\neval: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_ca7e98cc8d77\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrfParamGrid: Array[org.apache.spark.ml.param.ParamMap] =\nArray({\n\trfc_7cc4dc14d713-featureSubsetStrategy: onethird,\n\trfc_7cc4dc14d713-impurity: gini,\n\trfc_7cc4dc14d713-maxDepth: 5\n}, {\n\trfc_7cc4dc14d713-featureSubsetStrategy: onethird,\n\trfc_7cc4dc14d713-impurity: entropy,\n\trfc_7cc4dc14d713-maxDepth: 5\n}, {\n\trfc_7cc4dc14d713-featureSubsetStrategy: onethird,\n\trfc_7cc4dc14d713-impurity: gini,\n\trfc_7cc4dc14d713-maxDepth: 7\n}, {\n\trfc_7cc4dc14d713-featureSubsetStrategy: onethird,\n\trfc_7cc4dc14d713-impurity: entropy,\n\trfc_7cc4dc14d713-maxDepth: 7\n}, {\n\trfc_7cc4dc14d713-featureSubsetStrategy: sqrt,\n\trfc_7cc4dc14d713-impurity: gini,\n\trfc_7cc4dc14d713-maxDepth: 5\n}, {\n\trfc_7cc4dc14d713-featureSubsetStrategy: sqrt,\n\trfc_7cc4dc14d713-impurity: entropy,\n\trfc_7cc4dc14d713-maxDepth: 5\n}, {\n\trfc_7cc4dc...\nrfCv: org.apache.spark.ml.tuning.CrossValidator = cv_de5fcf604bb2\n\nrfCvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_de5fcf604bb2\n\nrfPredictions: org.apache.spark.sql.DataFrame = [AnimalID: string, Name: string ... 27 more fields]\n\nres5: Double = 0.6053303763067419\n"},"dateCreated":"2016-09-18T05:06:03-0400","dateStarted":"2016-09-19T09:54:02-0400","dateFinished":"2016-09-19T10:03:57-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:184"},{"text":"import org.apache.spark.ml.PipelineModel\n\n// Get the confusion matrix.\nMakeMulticlassMetrics(rfPredictions, FeatureVectorizer.indexed(labelCol), predictionCol).confusionMatrix\n\n// Let's figure out the feature importances.\nrfCvModel\n    .bestModel\n    .asInstanceOf[PipelineModel]\n    .stages(0)\n    .asInstanceOf[RandomForestClassificationModel]\n    .featureImportances\n    .toArray\n    .zip(featureVectorNames)\n    .sortWith(_._1 > _._1)\n    .map(_._2)\n    .take(10)","dateUpdated":"2016-09-19T09:53:33-0400","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474232763706_-35994099","id":"20160909-123308_556129312","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.PipelineModel\n\n\n\n\n\n\nres7: org.apache.spark.mllib.linalg.Matrix =\n2942.0  116.0   226.0  0.0  0.0\n909.0   1738.0  182.0  7.0  0.0\n825.0   151.0   447.0  2.0  0.0\n111.0   212.0   117.0  9.0  0.0\n10.0    43.0    4.0    0.0  0.0\n\nres8: Array[String] = Array(AgeInYears, isIntact Female, isIntact Male, isNeutered Male, isSpayed Female, isUnknown, isDog, isCat, isDomestic Shorthair Mix, isPit Bull Mix)\n"},"dateCreated":"2016-09-18T05:06:03-0400","dateStarted":"2016-09-19T09:54:14-0400","dateFinished":"2016-09-19T10:04:04-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:185"},{"text":"// The most important features are the agg, intact-ness, is dog, spayed-neutered. This makes sense given our exploratory data analysis.\n// The confusion matrix shows we are bad at predicting death and euthanization. I guess that makes sense because very few animals fall into those categories.\n// Let's try logistic regression and see if we get better performance.\nimport org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression, OneVsRest}\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.Pipeline\n\nval Array(lrTrain, lrTest) = preprocessedData.randomSplit(Array(0.7, 0.3))\n\nval lr = new LogisticRegression()\n    .setLabelCol(FeatureVectorizer.indexed(labelCol))\n    .setPredictionCol(predictionCol)\n    .setFeaturesCol(featuresCol)\n    .setMaxIter(20)\n    \nval lrOvr = new OneVsRest()\n    .setClassifier(lr)\n    .setLabelCol(FeatureVectorizer.indexed(labelCol))\n    .setPredictionCol(predictionCol)\n    .setFeaturesCol(featuresCol)\n    \nval lrPipeline = new Pipeline()\n    .setStages(Array(lrOvr, labelConverter))\n\nval eval = new MulticlassClassificationEvaluator()\n    .setLabelCol(FeatureVectorizer.indexed(labelCol))\n    .setPredictionCol(predictionCol)\n    .setMetricName(\"f1\")\n\nval lrParamGrid = new ParamGridBuilder()\n    .addGrid(lr.elasticNetParam, Array(0.3, 0.5, 0.7))\n    .addGrid(lr.fitIntercept, Array(false, true))\n    .addGrid(lr.regParam, Array(0.3, 0.5, 0.7))\n    .build()\n\nval lrCv = new CrossValidator()\n    .setEstimator(lrPipeline)\n    .setEstimatorParamMaps(lrParamGrid)\n    .setEvaluator(eval)\n    .setNumFolds(3)\n\nval lrCvModel = lrCv.fit(lrTrain)\nval lrPredictions = lrCvModel.transform(lrTest)\n\neval.evaluate(lrPredictions)\n\n// Get the confusion matrix.\nMakeMulticlassMetrics(lrPredictions, FeatureVectorizer.indexed(labelCol), predictionCol).confusionMatrix","dateUpdated":"2016-09-19T09:53:33-0400","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474232763708_-38302593","id":"20160910-111925_836752302","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.classification.{LogisticRegressionModel, LogisticRegression, OneVsRest}\n\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n\nimport org.apache.spark.ml.Pipeline\n\n\nlrTrain: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [AnimalID: string, Name: string ... 23 more fields]\nlrTest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [AnimalID: string, Name: string ... 23 more fields]\n\nlr: org.apache.spark.ml.classification.LogisticRegression = logreg_49e534bef672\n\nlrOvr: org.apache.spark.ml.classification.OneVsRest = oneVsRest_4e6ed7434946\n\nlrPipeline: org.apache.spark.ml.Pipeline = pipeline_826b6e755b74\n\neval: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_8e72fb02cc77\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlrParamGrid: Array[org.apache.spark.ml.param.ParamMap] =\nArray({\n\tlogreg_49e534bef672-elasticNetParam: 0.3,\n\tlogreg_49e534bef672-fitIntercept: false,\n\tlogreg_49e534bef672-regParam: 0.3\n}, {\n\tlogreg_49e534bef672-elasticNetParam: 0.3,\n\tlogreg_49e534bef672-fitIntercept: true,\n\tlogreg_49e534bef672-regParam: 0.3\n}, {\n\tlogreg_49e534bef672-elasticNetParam: 0.3,\n\tlogreg_49e534bef672-fitIntercept: false,\n\tlogreg_49e534bef672-regParam: 0.5\n}, {\n\tlogreg_49e534bef672-elasticNetParam: 0.3,\n\tlogreg_49e534bef672-fitIntercept: true,\n\tlogreg_49e534bef672-regParam: 0.5\n}, {\n\tlogreg_49e534bef672-elasticNetParam: 0.3,\n\tlogreg_49e534bef672-fitIntercept: false,\n\tlogreg_49e534bef672-regParam: 0.7\n}, {\n\tlogreg_49e534bef672-elasticNetParam: 0.3,\n\tlogreg_49e534bef672-fitIntercept: true,\n\tlogreg_49e534bef672-regP...\nlrCv: org.apache.spark.ml.tuning.CrossValidator = cv_5d4181946dd7\n\nlrCvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_5d4181946dd7\n\nlrPredictions: org.apache.spark.sql.DataFrame = [AnimalID: string, Name: string ... 25 more fields]\n\nres11: Double = 0.5166228440245955\n\n\n\n\n\n\nres12: org.apache.spark.mllib.linalg.Matrix =\n3205.0  104.0   1.0   0.0  0.0\n1133.0  1703.0  11.0  0.0  0.0\n1250.0  228.0   16.0  0.0  0.0\n179.0   286.0   9.0   0.0  0.0\n16.0    40.0    0.0   0.0  0.0\n"},"dateCreated":"2016-09-18T05:06:03-0400","dateStarted":"2016-09-19T10:03:57-0400","dateFinished":"2016-09-19T10:05:57-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:186"},{"text":"// Logistic regression did not perform as well as the random forest.","dateUpdated":"2016-09-19T09:53:34-0400","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474240870002_-2118302837","id":"20160918-192110_978410323","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-09-18T07:21:10-0400","dateStarted":"2016-09-19T10:04:04-0400","dateFinished":"2016-09-19T10:05:57-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:187"},{"text":"","dateUpdated":"2016-09-19T09:53:44-0400","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1474293214021_1365997498","id":"20160919-095334_1600623316","dateCreated":"2016-09-19T09:53:34-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:188"}],"name":"CleanedAnimalShelterOutcomes","id":"2BYNGYPZ5","angularObjects":{"2BWX7MJTF:shared_process":[],"2BVHYTJYP:shared_process":[],"2BWEBTUTW:shared_process":[],"2BWPZASG6:shared_process":[],"2BWQXPHNS:shared_process":[],"2BT8QV7PM:shared_process":[],"2BTRPYUT4:shared_process":[],"2BURKX4VZ:shared_process":[],"2BUVXP5U8:shared_process":[],"2BUDSSKHB:shared_process":[],"2BT8TPMDH:shared_process":[],"2BWB1RHPB:shared_process":[],"2BV9VA25T:shared_process":[],"2BUSB2N7B:shared_process":[],"2BTVG6HEX:shared_process":[],"2BVSR2BD5:shared_process":[],"2BX1SSNF8:shared_process":[],"2BWG8G75S:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}